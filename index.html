<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="ObscurePrompt: Jailbreaking Large Language Models via Obscure Input">
  <meta name="keywords" content="LLM, jailbreak, OOD, jailbreak defense">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ObscurePrompt: Jailbreaking Large Language Models via Obscure Input</title>
  <script type="module" src="https://md-block.verou.me/md-block.js"></script>


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./img/gui-logo.jpg">

  <link rel="stylesheet" href="./stylesheets/layout.css">
  <link rel="stylesheet" href="./stylesheets/index.css">
  <link rel="stylesheet" href="./bowe_componets/css/bootstrap.table.min.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <link href="./static/css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="./static/css/custom.css" media="screen" rel="stylesheet" type="text/css" />
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://howiehwong.github.io/">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://trustllmbenchmark.github.io/TrustLLM-Website/">
              TrustLLM
            </a>
            <a class="navbar-item" href="https://mllm-judge.github.io">
              MLLM-as-a-Judge
            </a>
            <a class="navbar-item" href="https://unigen-framework.github.io/">
              UniGen
            </a>
            <a class="navbar-item" href="https://honestllm.github.io">
              HonestyLLM
            </a>
            <a class="navbar-item" href="https://llm-coauthor.github.io/">
              LLM-as-a-Coauthor
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              ObscurePrompt: Jailbreaking Large Language Models via Obscure Input
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://howiehwong.github.io/">Yue Huang</a><sup
                  style="color:#2bff32;">1</sup><sup style="color:#ff2b67;">*</sup>,</span>
              <span class="author-block"><a href="https://jingyuhhh.github.io/">Jingyu Tang</a><sup
                  style="color:#ec8bfd;">2</sup><sup style="color:#ff2b67;">*</sup>,</span>
              <span class="author-block"><a href="https://dongping-chen.github.io/">Dongping Chen</a><sup
                  style="color:#ec8bfd;">2</sup><sup style="color:#ff2b67;">*</sup>,</span>
              <span class="author-block"><a href="https://tang-bd.github.io/">Bingda Tang</a><sup
                  style="color:#fabb55;">3</sup>,</span>
              <span class="author-block"><a href="http://wanyao.me/"><b>Yao Wan</b></a><sup
                  style="color:#ec8bfd;">2</sup>,</span>
              <span class="author-block"><a href="https://lichao-sun.github.io/"><b>Lichao Sun</b></a><sup
                  style="color:#66f1fb;">4</sup>,</span>
              <span class="author-block"><a href="https://engineering.nd.edu/faculty/xiangliang-zhang/"><b>Xiangliang
                    Zhang</b></a><sup style="color:#2bff32;">1</sup><sup style="color:#c9892e;">†</sup>,</span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup style="color:#2bff32;">1</sup>University of Notre Dame,</span>
              <span class="author-block"><sup style="color:#ec8bfd;">2</sup>Huazhong University of Science and
                Technology,</span>
              <span class="author-block"><sup style="color:#fabb55;">3</sup>Tsinghua University,</span>
              <span class="author-block"><sup style="color:#66f1fb;">4</sup>Lehigh University</span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">{<a href="mailto:yhuang37@nd.edu">yhuang37</a>, <a
                  href="mailto:xzhang33@nd.edu">xzhang33</a>}@nd.edu
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!--                <span class="link-block">-->
                <!--                  <a href="https://arxiv.org/pdf/2011.12948" class="external-link button is-normal is-rounded is-dark">-->
                <!--                    <span class="icon">-->
                <!--                      <i class="fas fa-file-pdf"></i>-->
                <!--                    </span>-->
                <!--                    <span>Paper</span>-->
                <!--                  </a>-->
                <!--                </span>-->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2406.13662" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <!--                <span class="link-block">-->
                <!--                  <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
                <!--                    class="external-link button is-normal is-rounded is-dark">-->
                <!--                    <span class="icon">-->
                <!--                      <i class="fab fa-youtube"></i>-->
                <!--                    </span>-->
                <!--                    <span>Video</span>-->
                <!--                  </a>-->
                <!--                </span>-->
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/HowieHwong/ObscurePrompt"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a href="https://huggingface.co/datasets/shuaishuaicdp/GUI-World"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span> -->
                <!-- Data Viewer. -->
                <!-- <span class="link-block">
                  <a href="https://huggingface.co/shuaishuaicdp/GUI-Vid" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-desktop"></i>
                    </span>
                    <span>Model</span>
                  </a>
                </span> -->
                <!-- Slides Link. -->
                <!-- <span class="link-block">
                  <a href="https://docs.google.com/presentation/d/1-r889Nb9n7SeZqrj-ryNqJLoMzp7aGNU2ihO8nUdEcE/edit?usp=sharing"
                    target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-google"></i>
                    </span>
                    <span>Slides</span>
                  </a>
                </span> -->
                <!-- Twitter Link. -->
                <!-- <span class="link-block">
                  <a href="https://twitter.com/TianbaoX/status/1778781521253667267" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-twitter"></i>
                    </span>
                    <span>Twitter</span>
                  </a>
                </span> -->
                <!-- Discord Link. -->
                <!-- <span class="link-block">
                  <a href="https://discord.gg/4Gnw7eTEZR" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-discord"></i>
                    </span>
                    <span>Discord</span>
                  </a>
                </span> -->

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- <section class="section">
    <div class="container is-max-desktop">
      <div class="column is-full">
        <video controls muted loop autoplay width="100%">
          <source src="static/videos/main.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </section> -->

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Main Figure. -->
      <h2 class="title is-3"></h2>
      <div class="content has-text-justified">
        <img src="img/op-framework.png" width="100%" alt="GUI-world Overview" class="responsive-image">
        <md-block>
          In this work, we introduces OBSCUREPROMPT, a novel method for jailbreaking LLMs by obscuring prompts to
          enhance attack robustness, demonstrating improved effectiveness over previous methods and maintaining efficacy
          against common defenses. Specifically, there are three-fold major contributions:
          <ol>
            <li><b>Observation about LLMs’ fragile alignment on OOD data.</b> By visualizing the representations of
              different queries within the hidden states of LLMs, we observed that OOD queries (i.e., obscure queries)
              can significantly weaken the ethical decision boundary. This observation strongly motivates our
              jailbreaking approach. </li>
            <li><b>A novel and simple jailbreak method.</b> We introduce a novel and straightforward approach named
              OBSCUREPROMPT to jailbreaking LLMs using obscure inputs. OBSCUREPROMPT is training-free and operates in a
              black-box setting, meaning it does not require access to the internal architecture of the target LLMs.
              This approach avoids the reliance on specific prompt templates, enhancing its feasibility and robustness
              for real-world applications. </li>
            <li><b>Comprehensive evaluation and empirical insights.</b> Comprehensive experiments are performed to
              validate the efficacy of our method, which demonstrates superior performance over existing baselines for
              both black-box and whitebox attacks. Other key findings from our experiments include: <ul>
                <li>The number of
                  integrated prompts significantly influences the attack success rate;</li>
                <li>Combining all types of jailbreak
                  strategies does not necessarily result in the most effective attack;</li>
                <li>Our proposed method remains
                  effective against mainstream defenses. The results confirm that LLMs remain vulnerable to obscure
                  inputs,
                  underscoring the need for enhanced defensive measures to secure LLMs against such vulnerabilities.
                </li>
              </ul>
            </li>
          </ol>
        </md-block>
      </div>
      <!--/ Main Figure. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-wdith">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <md-block>
              Recently, Large Language Models (LLMs) have garnered significant attention for their exceptional natural
              language processing capabilities. However, concerns about their trustworthiness remain unresolved,
              particularly in addressing “jailbreaking” attacks on aligned LLMs. Previous research predominantly relies
              on scenarios with white-box LLMs or specific and fixed prompt templates, which are often impractical and
              lack broad applicability. In this paper, we introduce a straightforward and novel method, named
              OBSCUREPROMPT, for jailbreaking LLMs, inspired by the observed fragile alignments in Out-of-Distribution
              (OOD) data. Specifically, we first formulate the decision boundary in the jailbreaking process and then
              explore how obscure text affects LLMs’ ethical decision boundary. OBSCUREPROMPT starts with constructing a
              base prompt that integrates wellknown jailbreaking techniques. Powerful LLMs are then utilized to obscure
              the original prompt through iterative transformations, aiming to bolster the attack’s robustness.
              Comprehensive experiments show that our approach substantially improves upon previous methods in terms of
              attack effectiveness, maintaining efficacy against two prevalent defense mechanisms. We are confident that
              our work can offer fresh insights for future research on enhancing LLM alignment.
            </md-block>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Environment Infrastructure. -->
      <h2 class="title is-3">Method: ObscurePrompt</h2>
      <img src="img/obscure_prompt2.png" width="100%" alt="Obscure-Prompt Examples" class="responsive-image">
      <div class="content has-text-justified">
        <md-block> Our approach
          comprises three primary components. Please see our paper for more details.
          <ol>
            <li>
              <b>Prompt Seed Curation:</b> To start with, we construct a robust base prompt by integrating several
              established jailbreak techniques, such as "Avoid Sorry".
            </li>
            <li> <b>Obscure-Guided Transformation:</b> Following a predefined instruction, we refine the base prompt by
              using GPT-4 to enhance its obscurity. </li>
            <li> <b>Attack Integration:</b> By iteratively repeating the
              aforementioned steps, we generate a series of obscure prompts, which are later employed to attack the
              target LLMs.</li>
          </ol>
        </md-block>
      </div>
      <!--/ Environment Infrastructure. -->
    </div>
  </section>

  <section>
    <div class="container is-max-desktop">

      <h2 class="title is-3">Experiments</h2>
      <div class="content has-text-justified">
        <ul>
          <li>
            <strong>Dataset.</strong> We use the advbench dataset in our experiments, which includes 521 harmful queries
            and has been widely used in previous studies.
          </li>
          <li>
            <strong>Models.</strong> We have carefully selected seven LLMs that are widely utilized, encompassing both
            open-source (i.e., open-weight) and proprietary models. The strategically chosen open-source models are
            Vicuna-7b, Llama2-7b, Llama2-70b, Llama3-8b, and Llama3-70b, and the proprietary models include ChatGPT and
            GPT-4. All target models’ temperatures are 0 as the recent study has compellingly revealed that the higher
            temperature will influence the attack performance. GPT-4 is used in the stage of obscure-guided
            transformation, and the temperature is set to 0.5 to ensure productivity and creativity simultaneously.
          </li>
          <li>
            <strong>Metrics.</strong> We use Attack Successful Rate (ASR) for our evaluation metric.
            To determine whether an attack successfully jailbreaks the LLM, we leverage the keywords matching method
            used in GCG and AutoDan.
          </li>
          <li>
            <strong>Baselines.</strong> We use three baselines with two white-box methods (GCG and AutoDAN) and one
            black-box method (DeepInception) that have been widely used in previous studies. The details of our
            baselines are shown in Appendix C.
          </li>
          <li>
            <strong>Jailbreak Prompt Types.</strong> We have selected four attack ways in the stage of prompt seed
            curation, which are widely used now: “Start With Specified Sentences”, “Forget Restraints”, “Avoid Sorry”,
            and “Direct Answer”.
          </li>
        </ul>
      </div>
    </div>
    <div class="cover" id="contentCover">
      <!-- Baseline. -->
      <div class="container-t">
        <div class="row">
          <div class="col-md-12">
            <div class="infoCard">
              <div class="infoBody">
                <div class="tabs is-centered example_lst">
                  <ul>
                    <li class="is-active"><a title="Overall">Overall</a></li>
                    <li><a title="Attack Types">Attack Types</a></li>
                    <li><a title="Robustness Against Defense">Robustness Against Defense</a></li>
                    <li><a title="Prompt Number">Prompt Number</a></li>
                  </ul>

                </div>
                <script type="text/javascript">
                  document.querySelectorAll(".example_lst li").forEach(e => {
                    e.addEventListener("click", Click_1)
                  })

                  function Click_1(eve) {
                    const iTxt = eve.srcElement.innerText
                    for (let v of document.querySelectorAll(".example_lst a")) {
                      if (iTxt === v.innerText) {
                        v.parentElement.className = "is-active";
                      } else {
                        v.parentElement.className = "";
                      }
                    }
                    for (let block of document.getElementsByClassName('lib_examples')) {
                      block.style.display = (block.title === iTxt) ? 'block' : 'none';
                    }
                  }

                </script>
                <div title="Overall" class="lib_examples" id="BoardPanel1" style="display: block;">
                  <!-- <div class="content has-text-justified"> -->
                  <md-block>
                    Comparison results with GCG, AutoDAN and DeepInception. Due to the large computing cost of
                    Llama2-70b and Llama3-70b, we do not conduct the experiments
                    of GCG and AutoDAN on it. Data in bold means the best attack performance.

                  </md-block>
                  <!-- </div> -->
                  <div class="table-container">
                    <table>
                      <thead>
                        <tr>
                          <th rowspan="2">Baseline</th>
                          <th colspan="5">Open-Source</th>
                          <th colspan="2">Proprietary</th>
                        </tr>
                        <tr>
                          <th>Vicuna-7b</th>
                          <th>Llama2-7b</th>
                          <th>Llama2-70b</th>
                          <th>Llama3-8b</th>
                          <th>Llama3-70b</th>
                          <th>ChatGPT</th>
                          <th>GPT-4</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td><a href="https://arxiv.org/abs/2307.15043" target="_blank">GCG</a></td>
                          <td>0.9710</td>
                          <td>0.4540</td>
                          <td>/</td>
                          <td>0.0120</td>
                          <td>/</td>
                          <td>/</td>
                          <td>/</td>
                        </tr>
                        <tr>
                          <td><a href="https://arxiv.org/abs/2310.04451" target="_blank">AutoDAN-GA</a></td>
                          <td><strong>0.9730</strong></td>
                          <td>0.5620</td>
                          <td>/</td>
                          <td>0.1721</td>
                          <td>/</td>
                          <td>/</td>
                          <td>/</td>
                        </tr>
                        <tr>
                          <td><a href="https://arxiv.org/abs/2310.04451" target="_blank">AutoDAN-HGA</a></td>
                          <td>0.9700</td>
                          <td>0.6080</td>
                          <td>/</td>
                          <td>0.1751</td>
                          <td>/</td>
                          <td>/</td>
                          <td>/</td>
                        </tr>
                        <tr>
                          <td><a href="https://arxiv.org/abs/2311.03191" target="_blank">DeepInception</a></td>
                          <td>0.9673</td>
                          <td>0.3051</td>
                          <td>0.1228</td>
                          <td>0.0096</td>
                          <td>0.0134</td>
                          <td>0.7024</td>
                          <td>0.2322</td>
                        </tr>
                        <tr>
                          <td><strong>OBSCUREPROMPT (Ours)</strong></td>
                          <td>0.9373</td>
                          <td><strong>0.6664</strong></td>
                          <td><strong>0.5082</strong></td>
                          <td><strong>0.3105</strong></td>
                          <td><strong>0.2552</strong></td>
                          <td><strong>0.8931</strong></td>
                          <td><strong>0.2697</strong></td>
                        </tr>
                      </tbody>
                    </table>
                  </div>
                </div>

                <div title="Attack Types" class="lib_examples" id="BoardPanel2" style="display: none;">
                  <!-- <div class="content has-text-justified"> -->
                  <md-block>
                    The influence of different attack types. FR: Forget Restraints, AS: Avoid Sorry, SW: Start With, DA:
                    Direct Answer. Data in bold means the best attack performance.
                  </md-block>
                  <!-- </div> -->

                  <div class="table-container">
                    <table>
                      <thead>
                        <tr>
                          <th rowspan="2">Model</th>
                          <th colspan="2">FR</th>
                          <th colspan="2">AS</th>
                          <th colspan="2">SW</th>
                          <th colspan="2">DA</th>
                          <th rowspan="2">All</th>
                        </tr>
                        <tr>
                          <th>w/o</th>
                          <th>only</th>
                          <th>w/o</th>
                          <th>only</th>
                          <th>w/o</th>
                          <th>only</th>
                          <th>w/o</th>
                          <th>only</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td class="bold">Vicuna-7b</td>
                          <td>0.9702</td>
                          <td>0.8280</td>
                          <td>0.9381</td>
                          <td>0.8784</td>
                          <td>0.9656</td>
                          <td>0.9770</td>
                          <td>0.9794</td>
                          <td>0.8990</td>
                          <td class="bold">1.0000</td>
                        </tr>
                        <tr>
                          <td class="bold">Llama2-7b</td>
                          <td>0.8440</td>
                          <td>0.3326</td>
                          <td>0.8784</td>
                          <td>0.6560</td>
                          <td>0.4954</td>
                          <td>0.8096</td>
                          <td class="bold">0.8876</td>
                          <td>0.2569</td>
                          <td>0.8371</td>
                        </tr>
                        <tr>
                          <td class="bold">Llama2-70b</td>
                          <td class="bold">0.8188</td>
                          <td>0.1927</td>
                          <td>0.7546</td>
                          <td>0.3945</td>
                          <td>0.3211</td>
                          <td>0.6193</td>
                          <td>0.5161</td>
                          <td>0.2041</td>
                          <td>0.7525</td>
                        </tr>
                        <tr>
                          <td class="bold">Llama3-8b</td>
                          <td>0.3463</td>
                          <td>0.3188</td>
                          <td>0.3028</td>
                          <td>0.2867</td>
                          <td>0.4037</td>
                          <td>0.2890</td>
                          <td>0.3440</td>
                          <td>0.1927</td>
                          <td class="bold">0.5245</td>
                        </tr>
                        <tr>
                          <td class="bold">Llama3-70b</td>
                          <td>0.1858</td>
                          <td>0.2294</td>
                          <td>0.1170</td>
                          <td class="bold">0.3922</td>
                          <td>0.2615</td>
                          <td>0.3119</td>
                          <td>0.2729</td>
                          <td>0.2706</td>
                          <td>0.2248</td>
                        </tr>
                        <tr>
                          <td class="bold">ChatGPT</td>
                          <td>0.9037</td>
                          <td>0.7156</td>
                          <td>0.9564</td>
                          <td>0.9725</td>
                          <td>0.8601</td>
                          <td class="bold">0.9794</td>
                          <td>0.8967</td>
                          <td>0.8899</td>
                          <td>0.8632</td>
                        </tr>
                        <tr>
                          <td class="bold">GPT-4</td>
                          <td>0.3073</td>
                          <td>0.1926</td>
                          <td>0.3165</td>
                          <td>0.3073</td>
                          <td>0.2752</td>
                          <td class="bold">0.3509</td>
                          <td>0.2597</td>
                          <td>0.1560</td>
                          <td>0.2900</td>
                        </tr>
                      </tbody>
                    </table>
                  </div>
                </div>

                <div title="Robustness Against Defense" class="lib_examples" id="BoardPanel3" style="display: none;">

                  <!-- <div class="content has-text-justified"> -->
                  <md-block>
                    <p>(Table) Attack performance (i.e., ASR) of OBSCUREPROMPT against paraphrase defense. We
                    consider the ASR based on the prompt of all attack types included.</p>
                    <p>(Figure)  Density distribution of different queries’ PPL
                      through GPT-2. The distribution
                      is visualized by Kernel Density Estimate.</p>
                  </md-block>
                  <!-- </div> -->

                  <div class="table-container">
                    <table>
                      <thead>
                        <tr>
                          <th rowspan="2">Paraphrasing Model</th>
                          <th colspan="2">Vicuna-7b</th>
                          <th colspan="2">Llama2-7b</th>
                          <th colspan="2">Llama2-70b</th>
                          <th colspan="2">Llama3-8b</th>
                          <th colspan="2">Llama3-70b</th>
                          <th colspan="2">ChatGPT</th>
                          <th colspan="2">GPT-4</th>
                        </tr>
                        <tr>
                          <th>Original</th>
                          <th>Para.</th>
                          <th>Original</th>
                          <th>Para.</th>
                          <th>Original</th>
                          <th>Para.</th>
                          <th>Original</th>
                          <th>Para.</th>
                          <th>Original</th>
                          <th>Para.</th>
                          <th>Original</th>
                          <th>Para.</th>
                          <th>Original</th>
                          <th>Para.</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td class="bold">ChatGPT</td>
                          <td>1.0000</td>
                          <td>0.6943</td>
                          <td>0.8371</td>
                          <td>0.4042</td>
                          <td>0.7525</td>
                          <td>0.2442</td>
                          <td>0.5245</td>
                          <td>0.1475</td>
                          <td>0.2248</td>
                          <td>0.2650</td>
                          <td>0.8632</td>
                          <td>0.5253</td>
                          <td>0.2900</td>
                          <td>0.2989</td>
                        </tr>
                        <tr>
                          <td class="bold">GPT-4</td>
                          <td>1.0000</td>
                          <td>0.7431</td>
                          <td>0.8371</td>
                          <td>0.3102</td>
                          <td>0.7525</td>
                          <td>0.2788</td>

                          <td>0.5245</td>
                          <td>0.1339</td>
                          <td>0.2248</td>
                          <td>0.1793</td>
                          <td>0.8632</td>
                          <td>0.6551</td>
                          <td>0.2900</td>
                          <td>0.1774</td>
                        </tr>
                      </tbody>
                    </table>
                  </div>

                  <img src="img/obscure_prompt3.png" alt="obscure_prompt1">
                </div>

                <div title="Prompt Number" class="lib_examples" id="BoardPanel4" style="display: none;">

                  <!-- <div class="content has-text-justified"> -->
                  <md-block>
                    ASR in different integrated prompt numbers.
                  </md-block>
                  <!-- </div> -->

                  <img src="img/obscure_prompt1.png" alt="obscure_prompt1" class="schoolLogo">
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" id="Experiment Result">
    <div class="container is-max-desktop">
      <div class="featurecard-container">
        <!-- Trustworthiness and Utility -->
        <h1 class="title">Experiment Results</h1>
        <div class="feature_1x1">
          <div class="featurecard">
            <h2>ObscurePrompt outperforms all baselines
              significantly.</h2>
          </div>
          <div class="description">
            <p>
              our method outperforms all other methods on the Llama2-7b, Llama2-70b, ChatGPT , and GPT-4. Particularly
              for the Llama2-70b model, our method improved the performance by approximately 38%, which demonstrates the
              effectiveness of OBSCUREPROMPT. It achieves a significantly high ASR at ChatGPT , which means the
              potential threat of our method for proprietary LLMs.
            </p>
          </div>
        </div>

        <!-- Alignment of LLMs -->
        <div class="feature_1x1">
          <div class="featurecard">
            <h2>Scaling laws in safety alignment indicate
              that larger parameters enhance LLM robustness against our attack.</h2>
          </div>
          <div class="description">
            <p>
              When comparing the ASR in models of different sizes, such as Llama2-7b versus Llama2-70b and Llama3-8b
              versus Llama3-70b, it is evident that ASR for larger LLMs is significantly higher, aligning with previous
              studies that larger LLMs may perform better in safety alignment.
            </p>
          </div>
        </div>

        <!-- Performance Gap in Trustworthiness -->
        <div class="feature_1x1">
          <div class="featurecard">
            <h2>The effect of the number of integrated prompts
              varies across different LLMs.</h2>
          </div>
          <div class="description">
            <p>
              GPT-4, in particular, demonstrates a steady rise in ASR with more complex attack prompts. Conversely, the
              growth in ASR for LLama series and ChatGPT begins to plateau as the number of prompts increases,
              suggesting a certain level of robustness against more complex attacks. For the Vicuna-7b, the ASR rises
              sharply from 1 to 2 prompts but stabilizes as the number continues to increase from 2 to 5.
            </p>
          </div>
        </div>


        <!-- Transparency in Trustworthiness -->
        <div class="feature_1x1">

          <div class="featurecard">
            <h2>Integrating all attack types may not yield a
              higher ASR.</h2>
          </div>
          <div class="description">
            <p>
              Except for the Vicuna-7b and Llama3-8b, most models do not achieve their highest ASR when all attack types
              are integrated into the prompt. This may be due to some LLMs experiencing safety alignment specifically
              against certain attack types. Notably, ChatGPT and GPT-4 reach their highest ASR using only the “Start
              with” attack type. This suggests that selecting the appropriate attack type significantly impacts the
              effectiveness of the attack, offering an area for future enhancement.
            </p>

          </div>
        </div>
      </div>
    </div>
  </section>
  <section class="section" id="Defense Against Attack">
    <div class="container is-max-desktop">
      <div class="featurecard-container">
        <!-- Trustworthiness and Utility -->
        <h1 class="title">Defense Against Attack</h1>
        <div class="feature_1x1">

          <div class="featurecard">
            <h2>Paraphrasing Defense. </h2>
          </div>
          <div class="description">
            <p>
              The effectiveness of paraphrasing as a defense mechanism against adversarial attacks is quantified by the
              changes in ASR for various LLMs. Notably, when comparing the original and paraphrased prompts, all models
              demonstrate a decrease in ASR, with the most significant reduction observed in Llama2-70b (from 0.7525 to
              0.2442). This suggests that paraphrasing generally reduces the models’ vulnerabilities to our proposed
              attack. We found that the main reason for this ASR decrease is that the prompt after paraphrasing is not
              as obscure as the original, making it easier to understand and thus reducing the effectiveness of obscure
              input. However, despite the reduction, the residual ASR, notably the 17.74% for GPT-4’s and 52.54% for
              ChatGPT , indicates a remaining risk. The variance in the impact of paraphrasing on different models
              suggests that the models’ underlying architectures and training data might influence their resilience to
              such attacks. These results underscore the importance of developing more robust models that maintain high
              resistance to adversarial inputs across both original and paraphrased prompts. </p>

          </div>
        </div>
        <div class="feature_1x1">

          <div class="featurecard">
            <h2>PPL filtering Defense.</h2>
          </div>
          <div class="description">
            <p>
              As depicted in Figure, it is evident that the average PPL associated with obscure harmful queries or
              prompts significantly exceeds that of harmless or original harmful queries. Moreover, an overlap is
              observed between the distributions of harmless queries and fully obscured harmful prompts. This overlap
              suggests that relying solely on a PPL-based filter may not provide an effective defense against such
              attacks, as it could potentially compromise the processing of benign user queries (i.e., harmless
              queries). This also indicates that OBSCUREPROMPT is robust to PPL-filtering defender.</p>

          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h1 class="title">BibTeX</h1>
      <pre><code>@misc{huang2024obscurepromptjailbreakinglargelanguage,
        title={ObscurePrompt: Jailbreaking Large Language Models via Obscure Input}, 
        author={Yue Huang and Jingyu Tang and Dongping Chen and Bingda Tang and Yao Wan and Lichao Sun and Xiangliang Zhang},
        year={2024},
        eprint={2406.13662},
        archivePrefix={arXiv},
        primaryClass={cs.CL},
        url={https://arxiv.org/abs/2406.13662}, 
  }</code></pre>
    </div>
  </section>
  <div class="content">
    <div id="supportContainer">
      <h1 class="supportTitle">ObscurePrompt Team</h1>
      <br>

      <div id="logoContainer">
        <img src="img/logos/ND.png" alt="School 3" class="schoolLogo">
        <img src="img/logos/HUST.png" alt="School 1" class="schoolLogo">
        <img src="img/logos/Tsinghua.png" alt="School 4" class="schoolLogo">
        <img src="img/logos/Lehigh-University-logo.png" alt="School 2" class="schoolLogo">

      </div>


    </div>
  </div>
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>. This means you are free to borrow the <a
                href="https://github.com/nerfies/nerfies.github.io">source
                code</a> of this website,
              we just ask that you link back to this page in the footer.
            </p>
            <p>This website is based on templates in <a
                href="https://trustllmbenchmark.github.io/TrustLLM-Website/">TrustLLM</a> and
              <a href="https://os-world.github.io/">OSWorld</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>